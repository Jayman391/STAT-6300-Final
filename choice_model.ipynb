{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "from math import floor\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T21:15:53.923576Z",
     "start_time": "2023-11-28T21:15:53.501095Z"
    }
   },
   "outputs": [],
   "source": [
    "# globals\n",
    "g_y = []\n",
    "g_y_pred = []\n",
    "g_num_groups = 0\n",
    "g_users = []\n",
    "\n",
    "class Simulation:\n",
    "\n",
    "    ## Fixed hyperparameters\n",
    "    initial_users = 20\n",
    "    initial_groups = 10\n",
    "    initial_communities = 5\n",
    "\n",
    "    # group and community preferences\n",
    "    alpha_group_hyperparameter = 10\n",
    "    beta_group_hyperparameter = 10 \n",
    "\n",
    "    alpha_community_hyperparameter = 10\n",
    "    beta_community_hyperparameter = 10\n",
    "\n",
    "        \n",
    "    # Initialize lists to store users and groups\n",
    "    users = []\n",
    "    groups = []\n",
    "    communities = []\n",
    "\n",
    "\n",
    "    gis = {}\n",
    "    cis = {}\n",
    "    uis = {}\n",
    "\n",
    "    def __init__(self,num_timesteps, user_growth_rate, interaction_threshold, new_group_rate, new_community_rate) -> None:\n",
    "\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        self.user_growth_rate = user_growth_rate\n",
    "\n",
    "        self.interaction_threshold = interaction_threshold\n",
    "\n",
    "        self.new_group_rate = new_group_rate\n",
    "        self.new_group_join_chance = new_group_rate / 10\n",
    "\n",
    "        self.new_community_rate = new_community_rate\n",
    "        self.new_community_join_chance = new_community_rate / 10\n",
    "\n",
    "        self.same_community_interaction_ratio = new_community_rate * new_group_rate\n",
    "\n",
    "    class Community:\n",
    "        def __init__(self, simulation, group=None):\n",
    "            self.simulation = simulation \n",
    "            # Initialize a community with a list of users and groups\n",
    "            self.id = len(self.simulation.communities) + 1\n",
    "            self.groups = [group] if group else []\n",
    "            self.interactions = []\n",
    "\n",
    "    class Group:\n",
    "        def __init__(self, simulation):\n",
    "            self.simulation = simulation \n",
    "            # Initialize a group with an ID and a dictionary tgo track user interactions\n",
    "            self.id = len(self.simulation.groups)\n",
    "            self.interactions = {}\n",
    "            self.community = None\n",
    "\n",
    "        def join_community(self, community):\n",
    "            community.groups.append(self)\n",
    "            self.community = community\n",
    "\n",
    "    class User:\n",
    "        def __init__(self, group_alpha, group_beta, community_alpha, community_beta):\n",
    "            # Initialize a user with ID, group memberships, interaction history, and Beta distribution preferences\n",
    "            self.id = None\n",
    "\n",
    "            self.groups = []\n",
    "            self.communities = []\n",
    "            self.interaction_history = []\n",
    "\n",
    "            self.group_preferences = stats.beta(group_alpha, group_beta)\n",
    "            self.community_preferences = stats.beta(community_alpha, community_beta)\n",
    "            self.updated_preferences = np.array([1])\n",
    "\n",
    "        def update_preferences(self):\n",
    "            # Update user's preferences based on group interactions\n",
    "            if not self.groups:\n",
    "                self.updated_preferences = np.array([1])\n",
    "                return\n",
    "            else:\n",
    "                #sort groups by number of interactions\n",
    "                self.groups.sort(key=lambda group: len(group.interactions))\n",
    "\n",
    "            total_size = sum([len(group.interactions) for group in self.groups])\n",
    "\n",
    "            # if size is 0, this must be the first iteration, return uniform\n",
    "            if total_size == 0:\n",
    "                self.ccdf = np.array([1])\n",
    "                return\n",
    "            else:\n",
    "                sizes = sorted([len(group.interactions) for group in self.groups])\n",
    "                self.ccdf = 1 - (np.cumsum(sizes) / total_size)\n",
    "\n",
    "            group_convolution = np.convolve(self.group_preferences.pdf(np.linspace(0, 1, len(self.groups))), self.ccdf , mode='same')\n",
    "\n",
    "            self.updated_preferences = np.convolve(group_convolution, self.community_preferences.pdf(np.linspace(0, 1, len(self.groups))), mode='same')\n",
    "\n",
    "            if np.isnan(self.updated_preferences).any() or np.sum(self.updated_preferences) == 0:\n",
    "                self.updated_preferences = np.array([1 / len(self.groups)] * len(self.groups))\n",
    "            else:\n",
    "                self.updated_preferences /= np.sum(self.updated_preferences)\n",
    "\n",
    "        def join_group(self, group):\n",
    "            # Add a group to the user's group list and set initial interactions to 0\n",
    "            self.groups.append(group)\n",
    "            group.interactions[self] = 0\n",
    "\n",
    "        def interact(self, group):\n",
    "            # Record an interaction with the specified group\n",
    "            group.interactions[self] = group.interactions.get(self, 0) + 1\n",
    "            self.interaction_history.append(group.id)\n",
    "\n",
    "    # Recalculate probabilities at every iteration or after any changes\n",
    "    def calculate_probabilities(self):\n",
    "        global community_relative_frequency, group_relative_frequency\n",
    "\n",
    "        community_relative_frequency = np.array([len(community.groups) for community in self.communities], dtype=float)\n",
    "        # if community_relative_frequency.sum() != 0:\n",
    "        community_relative_frequency += 1e-5  # Avoid division by zero\n",
    "        community_relative_frequency /= community_relative_frequency.sum()\n",
    "\n",
    "        group_relative_frequency = np.array([sum(group.interactions.values()) for group in self.groups], dtype=float)\n",
    "        # if group_relative_frequency.sum() != 0:\n",
    "        group_relative_frequency += 1e-5\n",
    "        group_relative_frequency /= group_relative_frequency.sum()\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "\n",
    "        # Initialize users\n",
    "        for i in range(self.initial_users):\n",
    "            self.users.append(\n",
    "                self.User(\n",
    "                    self.alpha_group_hyperparameter,\n",
    "                    self.beta_group_hyperparameter,\n",
    "                    self.alpha_community_hyperparameter,\n",
    "                    self.beta_community_hyperparameter,\n",
    "                )\n",
    "            )\n",
    "            self.users[-1].id = len(self.users)\n",
    "\n",
    "        # Initialize communities\n",
    "        for i in range(self.initial_communities):\n",
    "            self.communities.append(self.Community(self))\n",
    "\n",
    "        # Initialize groups\n",
    "        for i in range(self.initial_groups):\n",
    "            self.groups.append(self.Group(self))\n",
    "\n",
    "        # adding the first groups to each community so there is at least one group in each community\n",
    "        for i in range(len(self.communities)):\n",
    "            self.groups[i].join_community(self.communities[i])\n",
    "            # random chance for each user to join the first group of a new community\n",
    "            for user in self.users:\n",
    "                if np.random.random() < self.new_community_join_chance:\n",
    "                    user.join_group(self.groups[i])\n",
    "\n",
    "        # randomly adding the rest of the groups to communities\n",
    "        for group in self.groups[len(self.communities):]:\n",
    "            group.join_community(self.communities[np.random.randint(0, len(self.communities))])\n",
    "            for user in self.users:\n",
    "                if np.random.random() < self.new_group_join_chance:\n",
    "                    user.join_group(group)\n",
    "\n",
    "        # initialize dictionaries for each group, community, and user\n",
    "        for group in self.groups:\n",
    "            self.gis[group.id] = []\n",
    "        for community in self.communities:\n",
    "            self.cis[community.id] = []\n",
    "        for user in self.users:\n",
    "            self.uis[user.id] = []\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        # main loop\n",
    "        for time in range(self.num_timesteps):\n",
    "            if time % 10 == 0:\n",
    "                print(f\"Time: {time}\")\n",
    "            # Calculate probabilities\n",
    "            self.calculate_probabilities()\n",
    "\n",
    "            # Add new users\n",
    "            new_users_count = floor(np.random.exponential(self.user_growth_rate))\n",
    "            for i in range(new_users_count):\n",
    "                self.users.append(\n",
    "                    self.User(\n",
    "                        self.alpha_group_hyperparameter,\n",
    "                        self.beta_group_hyperparameter,\n",
    "                        self.alpha_community_hyperparameter,\n",
    "                        self.beta_community_hyperparameter,\n",
    "                    )\n",
    "                )\n",
    "                self.users[-1].id = len(self.users)\n",
    "\n",
    "            # Add new groups\n",
    "            new_groups_count = floor(np.random.exponential(self.new_group_rate))\n",
    "            for i in range(new_groups_count):\n",
    "                self.groups.append(self.Group(self))\n",
    "\n",
    "                # a new community always get made on the first time step\n",
    "                if time == 0:\n",
    "                    if new_groups_count == 0:\n",
    "                        self.groups.append(self.Group(self))\n",
    "                    self.groups[-1].join_community(self.communities[-1])\n",
    "                    self.communities[-1].groups.append(self.groups[-1])\n",
    "                else:\n",
    "                    # check if the new group forms a new community\n",
    "                    if np.random.random() < self.new_community_rate:\n",
    "                        self.communities.append(self.Community(self, self.groups[-1]))\n",
    "                        self.groups[-1].community = self.communities[-1]\n",
    "                        # each user has a chance to join the new community\n",
    "                        for user in self.users:\n",
    "                            if np.random.random() < self.new_community_join_chance:\n",
    "                                user.join_group(self.groups[-1])\n",
    "                        # users[np.random.randint(0, len(users))].join_group(groups[-1])\n",
    "                    else:\n",
    "                        # join a random community\n",
    "                        self.groups[-1].join_community(self.communities[np.random.randint(0, len(self.communities))])\n",
    "\n",
    "            # Updating dictionaries with new groups, communities, and users\n",
    "            # and setting their initial values to 0\n",
    "            for group in self.groups:\n",
    "                if group.id not in self.gis:\n",
    "                    self.gis[group.id] = [0]\n",
    "                self.gis[group.id].append(0)\n",
    "            for community in self.communities:\n",
    "                if community.id not in self.cis:\n",
    "                    self.cis[community.id] = [0]\n",
    "                self.cis[community.id].append(0)\n",
    "            for user in self.users:\n",
    "                if user.id not in self.uis:\n",
    "                    self.uis[user.id] = [0]\n",
    "                self.uis[user.id].append(0)\n",
    "\n",
    "            # Add new users to groups\n",
    "            for user in self.users:\n",
    "                self.calculate_probabilities()\n",
    "                # if there are groups for the user to join that they aren't in\n",
    "                if len(user.groups) < len(self.groups):\n",
    "                    # join a group\n",
    "                    if np.random.random() < self.new_group_join_chance:\n",
    "                        user.join_group(self.groups[np.random.choice(len(self.groups), p=group_relative_frequency)])\n",
    "\n",
    "            # Interact with groups\n",
    "            for user in self.users:\n",
    "                user.update_preferences()\n",
    "                interacted_groups = []\n",
    "                if np.random.uniform() < self.interaction_threshold and user.groups:\n",
    "                    # print(user.updated_preferences)\n",
    "                    group = np.random.choice(user.groups, p=user.updated_preferences)\n",
    "                    user.interact(group)\n",
    "                    self.gis[group.id][-1] += 1\n",
    "                    self.cis[group.community.id][-1] += 1\n",
    "                    self.uis[user.id][-1] += 1\n",
    "\n",
    "                    # potential bonus interactions within another group in the same community\n",
    "                    if group.community:\n",
    "                        while True:\n",
    "                            if np.random.uniform() < self.same_community_interaction_ratio:\n",
    "                                community = group.community                    \n",
    "                                group = np.random.choice(community.groups)\n",
    "                                user.interact(group)\n",
    "                                self.gis[group.id][-1] += 1\n",
    "                                self.cis[group.community.id][-1] += 1\n",
    "                                self.uis[user.id][-1] += 1\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "            # Update user preferences\n",
    "            for user in self.users:\n",
    "                if user.groups:\n",
    "                    user.update_preferences()\n",
    "                    if user.id == 0:\n",
    "                        print(user.updated_preferences)\n",
    "                        print(user.group_preferences.pdf(np.linspace(0, 1, len(user.groups))))\n",
    "                else:\n",
    "                    user.updated_preferences = np.array([1])\n",
    "\n",
    "    def plot(self, sim_number):        \n",
    "        directory_name = f\"{self.user_growth_rate}_{self.interaction_threshold}_{self.new_group_rate}_{self.new_community_rate}/{sim_number}\"\n",
    "        os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "        c_sum = []\n",
    "        c_sum_labels = []\n",
    "        for i in range(len(self.communities)):\n",
    "            temp_sum = [0] * self.num_timesteps\n",
    "            c_vals = np.cumsum(self.cis[i+1])\n",
    "            # add the values starting from the back\n",
    "            for j, val in enumerate(reversed(c_vals)):\n",
    "                temp_sum[-1-j] = val\n",
    "            c_sum.append(temp_sum)\n",
    "            c_sum_labels.append(list(self.cis.keys())[i])\n",
    "\n",
    "        # print the final value for each community\n",
    "        for c in c_sum_labels[:5]:\n",
    "            print(c, c_sum[c_sum_labels.index(c)][-1])\n",
    "            \n",
    "        # finding the labels for the 5 largest communities\n",
    "        top_5 = []\n",
    "        top_5_labels = []\n",
    "        for i in range(5):\n",
    "            max_val = 0\n",
    "            max_index = 0\n",
    "            for j in range(len(c_sum)):\n",
    "                if c_sum[j][-1] > max_val and c_sum_labels[j] not in top_5_labels:\n",
    "                    max_val = c_sum[j][-1]\n",
    "                    max_index = j\n",
    "            top_5.append(c_sum[max_index])\n",
    "            top_5_labels.append(c_sum_labels[max_index])\n",
    "\n",
    "        for i in range(len(c_sum)):\n",
    "            if c_sum_labels[i] in top_5_labels:\n",
    "                plt.plot(c_sum[i][:len(c_sum[i])], label=f\"C{i+1}\")\n",
    "            else:\n",
    "                plt.plot(c_sum[i][:len(c_sum[i])], label=None)\n",
    "\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Cumulative Interactions\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.title(\"Cumulative Interactions of Each Community Over Time\")\n",
    "        plt.savefig(f\"{directory_name}/community_interaction_growth.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Scatter plot for final amount of interactions for each community\n",
    "        c_sum_final = []\n",
    "        c_sum_final_labels = []\n",
    "        for i in range(len(self.communities)):\n",
    "            c_sum_final.append(c_sum[i][-1])\n",
    "            c_sum_final_labels.append(list(self.cis.keys())[i])\n",
    "\n",
    "        plt.scatter(c_sum_final_labels, c_sum_final)\n",
    "        plt.xlabel(\"Community\")\n",
    "        plt.ylabel(\"Final Cumulative Interactions\")\n",
    "        plt.title(\"Final Cumulative Interactions of Each Community\")\n",
    "        plt.savefig(f\"{directory_name}/final_community_interactions.png\")\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "        g_sum = []\n",
    "        g_sum_labels = []\n",
    "        for i in range(1, len(self.groups)):\n",
    "            temp_sum = [0] * self.num_timesteps\n",
    "            g_vals = np.cumsum(self.gis[i])\n",
    "            # add the values starting from the back\n",
    "            for j, val in enumerate(reversed(g_vals)):\n",
    "                try:\n",
    "                    temp_sum[j] = val\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            temp_sum = temp_sum[::-1]\n",
    "            g_sum.append(temp_sum)\n",
    "            g_sum_labels.append(list(self.gis.keys())[i])\n",
    "\n",
    "        # print the final value for each group\n",
    "        for g in g_sum_labels[:5]:\n",
    "            print(g, g_sum[g_sum_labels.index(g)][-1])\n",
    "\n",
    "        # finding the labels for the 5 largest groups\n",
    "        top_5 = []\n",
    "        top_5_labels = []\n",
    "        for i in range(5):\n",
    "            max_val = 0\n",
    "            max_index = 0\n",
    "            for j in range(len(g_sum)):\n",
    "                if g_sum[j][-1] > max_val and g_sum_labels[j] not in top_5_labels:\n",
    "                    max_val = g_sum[j][-1]\n",
    "                    max_index = j\n",
    "            top_5.append(g_sum[max_index])\n",
    "            top_5_labels.append(g_sum_labels[max_index])\n",
    "\n",
    "        for i in range(len(g_sum)):\n",
    "            if g_sum_labels[i] in top_5_labels:\n",
    "                plt.plot(g_sum[i], label=f\"G{i+1}\")\n",
    "            else:\n",
    "                plt.plot(g_sum[i], label=None)\n",
    "\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Cumulative Interactions\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.ylim(bottom=1)\n",
    "        plt.title(\"Cumulative Interactions of Each Group Over Time\")\n",
    "        plt.savefig(f\"{directory_name}/group_interaction_growth.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Scatter plot for final amount of interactions for each group\n",
    "        g_sum_final = []\n",
    "        g_sum_final_labels = []\n",
    "        for i in range(len(g_sum)):\n",
    "            g_sum_final.append(g_sum[i][-1])\n",
    "            g_sum_final_labels.append(list(self.gis.keys())[i])\n",
    "\n",
    "        plt.scatter(g_sum_final_labels, g_sum_final)\n",
    "        plt.xlabel(\"Group\")\n",
    "        plt.ylabel(\"Final Cumulative Interactions\")\n",
    "        plt.title(\"Final Cumulative Interactions of Each Group\")\n",
    "        plt.savefig(f\"{directory_name}/final_group_interactions.png\")\n",
    "        plt.close()\n",
    "\n",
    "        for u in self.uis:\n",
    "            self.uis[u] = self.uis[u][:self.num_timesteps]\n",
    "\n",
    "        # plotting total amount of interactions for each user\n",
    "        u_sum = []\n",
    "        u_sum_labels = []\n",
    "        for i in range(1, len(self.users)):\n",
    "            temp_sum = [0] * self.num_timesteps\n",
    "            u_vals = np.cumsum(self.uis[i])\n",
    "            # add the values starting from the back\n",
    "            for j, val in enumerate(reversed(u_vals)):\n",
    "                temp_sum[j] = val\n",
    "\n",
    "            temp_sum = temp_sum[::-1]\n",
    "            u_sum.append(temp_sum)\n",
    "            u_sum_labels.append(list(self.uis.keys())[i])\n",
    "\n",
    "        # print the final value for each user\n",
    "        for u in u_sum_labels[:5]:\n",
    "            print(u, u_sum[u_sum_labels.index(u)][-1])\n",
    "\n",
    "        # finding the labels for the 5 largest users\n",
    "        top_5 = []\n",
    "        top_5_labels = []\n",
    "\n",
    "        for i in range(5):\n",
    "            max_val = 0\n",
    "            max_index = 0\n",
    "            for j in range(len(u_sum)):\n",
    "                if u_sum[j][-1] > max_val and u_sum_labels[j] not in top_5_labels:\n",
    "                    max_val = u_sum[j][-1]\n",
    "                    max_index = j\n",
    "            top_5.append(u_sum[max_index])\n",
    "            top_5_labels.append(u_sum_labels[max_index])\n",
    "\n",
    "        # Scatter plot for final amount of interactions for each user\n",
    "        u_sum_final = []\n",
    "        u_sum_final_labels = []\n",
    "        for i in range(len(u_sum)):\n",
    "            u_sum_final.append(u_sum[i][-1])\n",
    "            u_sum_final_labels.append(list(self.uis.keys())[i])\n",
    "\n",
    "        plt.scatter(u_sum_final_labels, u_sum_final)\n",
    "        plt.xlabel(\"User\")\n",
    "        plt.ylabel(\"Final Cumulative Interactions\")\n",
    "        plt.title(\"Cumulative Interactions of Each User\")\n",
    "        plt.savefig(f\"{directory_name}/final_user_interactions.png\")\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    def write_data(self, sim_number):\n",
    "        directory_name = f\"{self.user_growth_rate}_{self.interaction_threshold}_{self.new_group_rate}_{self.new_community_rate}/{sim_number}\"\n",
    "        os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "        # Write User Interactions to CSV\n",
    "        with open(f\"{directory_name}/user_interactions.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row in self.uis:\n",
    "                writer.writerow([row] + self.uis[row])\n",
    "\n",
    "            file.close()\n",
    "        \n",
    "        # Write Group Interactions to CSV\n",
    "        with open(f\"{directory_name}/group_interactions.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row in self.gis:\n",
    "                writer.writerow([row] + self.gis[row])\n",
    "\n",
    "            file.close()\n",
    "\n",
    "        # Write Community Interactions to CSV\n",
    "        with open(f\"{directory_name}/community_interactions.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row in self.cis:\n",
    "                writer.writerow([row] + self.cis[row])\n",
    "\n",
    "            file.close()\n",
    "\n",
    "\n",
    "        with open(f\"{directory_name}/simulation_data.csv\", 'w') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['num_users', 'num_groups', 'num_communities', 'num_interactions'])\n",
    "            writer.writerow([len(self.users), len(self.groups), len(self.communities), sum([len(group.interactions) for group in self.groups])])\n",
    "\n",
    "            file.close()\n",
    "\n",
    "        print(\"Data written to CSV files.\")\n",
    "\n",
    "    def community_regression_model(self, sim_number): \n",
    "        directory_name = f\"{self.user_growth_rate}_{self.interaction_threshold}_{self.new_group_rate}_{self.new_community_rate}/{sim_number}\"\n",
    "        os.makedirs(directory_name, exist_ok=True)\n",
    "         # Initialize DataFrame with a consistent index\n",
    "        X = pd.DataFrame(index=range(self.num_timesteps))\n",
    "\n",
    "        # Constructing DataFrame X\n",
    "        for community_id in range(1, len(self.communities) + 1):  # Group IDs are 1-indexed\n",
    "            # Retrieve group data and handle missing values\n",
    "            df = pd.DataFrame(self.cis[community_id]).fillna(0)\n",
    "            if len(df) < self.num_timesteps:\n",
    "                df = df.reindex(range(self.num_timesteps), fill_value=0)\n",
    "            X[f'community_{community_id}'] = df.squeeze()\n",
    "        \n",
    "        X = X.T\n",
    "\n",
    "        # Target variable y (last column of X)\n",
    "        y = X.iloc[:, -1].to_numpy()\n",
    "\n",
    "        # Features (all columns except the last)\n",
    "        X = X.iloc[:, :-1]\n",
    "\n",
    "        print(X)\n",
    "\n",
    "        # PyMC model\n",
    "        model = pm.Model()\n",
    "        with model:\n",
    "            try:\n",
    "                # Priors for unknown model parameters\n",
    "                alpha = pm.TruncatedNormal('alpha', lower=0, mu=0.5, sigma=10, shape=X.shape[0])\n",
    "                betas = pm.Normal('betas', mu=0.05, sigma=0.05, shape=X.shape[1])\n",
    "\n",
    "                # Expected value of outcome\n",
    "                mu = alpha + pm.math.dot(X, betas)\n",
    "\n",
    "                # Likelihood (sampling distribution) of observations\n",
    "                sigma = pm.Exponential('sigma', lam=1, shape=X.shape[0])\n",
    "                y_obs = pm.TruncatedNormal('y_obs', lower=0, mu=mu, sigma=sigma, observed=y, shape=X.shape[0])\n",
    "\n",
    "                # Sampling\n",
    "                trace = pm.sample(tune=5000,draws=5000, return_inferencedata=True)\n",
    "                posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "                prior_predictive = pm.sample_prior_predictive()\n",
    "\n",
    "\n",
    "            except pm.exceptions.SamplingError as e:\n",
    "                print(f\"Sampling error: {e}\")\n",
    "\n",
    "        prior = prior_predictive['prior_predictive']['y_obs']\n",
    "\n",
    "         # Check the shape of the prior predictive\n",
    "        print(\"Shape of prior predictive:\", prior.shape)\n",
    "\n",
    "        # Adjust the code based on the shape of prior\n",
    "        num_chains, num_draws, num_communities = prior.shape\n",
    "        cs = [[] for _ in range(num_communities)]\n",
    "\n",
    "        for chain in range(num_chains):\n",
    "            for draw in range(num_draws):\n",
    "                for c in range(num_communities):\n",
    "                    cs[c].append(prior[chain, draw, c])\n",
    "\n",
    "\n",
    "        for c in cs:\n",
    "            plt.hist(c)\n",
    "        plt.show()\n",
    "\n",
    "        pred = posterior_predictive['posterior_predictive']['y_obs'].to_numpy()\n",
    "\n",
    "        shape = pred.shape\n",
    "        comms = shape[2]\n",
    "\n",
    "        # Initialize list of lists for each community\n",
    "        preds = [[] for _ in range(comms)]\n",
    "\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                for k in range(comms):\n",
    "                    preds[k].append(pred[i, j, k])\n",
    "\n",
    "        for k in range(comms):\n",
    "\n",
    "            plt.hist(preds[k], bins=50, alpha=0.5)\n",
    "            plt.axvline(y[k], color='k', linestyle='dashed', linewidth=1)\n",
    "            plt.title('Community Interaction Predictions')\n",
    "            plt.xlabel(\"Number of interactions\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "            \n",
    "        print(az.summary(trace))\n",
    "\n",
    "        az.plot_trace(trace)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        trace_df = az.summary(trace)\n",
    "        trace_df.to_csv(f'{directory_name}/community_trace.csv')\n",
    "\n",
    "    \n",
    "    def group_regression_model(self,sim_number):\n",
    "        directory_name = f\"{self.user_growth_rate}_{self.interaction_threshold}_{self.new_group_rate}_{self.new_community_rate}/{sim_number}\"\n",
    "        os.makedirs(directory_name, exist_ok=True)\n",
    "        \n",
    "        X = pd.DataFrame(index=range(self.num_timesteps))\n",
    "\n",
    "        # Constructing DataFrame X\n",
    "        for group_id in range(1, len(self.groups) + 1):  # Group IDs are 1-indexed\n",
    "            # Retrieve group data and handle missing values\n",
    "            df = pd.DataFrame(self.gis[group_id]).fillna(0)\n",
    "            if len(df) < self.num_timesteps:\n",
    "                df = df.reindex(range(self.num_timesteps), fill_value=0)\n",
    "            X[f'group_{group_id}'] = df.squeeze()\n",
    "        \n",
    "        X = X.T\n",
    "\n",
    "        # Target variable y (last column of X)\n",
    "        y = X.iloc[:, -1].to_numpy()\n",
    "\n",
    "        # Features (all columns except the last)\n",
    "        X = X.iloc[:, :-1]\n",
    "\n",
    "        print(X)\n",
    "\n",
    "        model = pm.Model()\n",
    "\n",
    "        with model:\n",
    "            try:\n",
    "                # Priors for unknown model parameters\n",
    "                alpha = pm.TruncatedNormal('alpha', lower=0, mu=0.5, sigma=10, shape=X.shape[0])\n",
    "                betas = pm.Normal('betas', mu=0.05, sigma=0.05, shape=X.shape[1])\n",
    "\n",
    "                # Expected value of outcome\n",
    "                mu = alpha + pm.math.dot(X, betas)\n",
    "\n",
    "                # Likelihood (sampling distribution) of observations\n",
    "                sigma = pm.Exponential('sigma', lam=1, shape=X.shape[0])\n",
    "                y_obs = pm.TruncatedNormal('y_obs', lower=0, mu=mu, sigma=sigma, observed=y, shape=X.shape[0])\n",
    "\n",
    "                # Sampling\n",
    "                trace = pm.sample(tune=5000,draws=5000, return_inferencedata=True)\n",
    "                posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "                prior_predictive = pm.sample_prior_predictive()\n",
    "            \n",
    "            except pm.exceptions.SamplingError:\n",
    "                warnings.warn('SamplingError: Skipping this group')\n",
    "\n",
    "        prior = prior_predictive['prior_predictive']['y_obs']\n",
    "\n",
    "        gs = [[] for _ in range(len(self.groups))]\n",
    "\n",
    "        for chain in range(prior.shape[0]):\n",
    "            for draw in range(prior.shape[1]):\n",
    "                for g in range(prior.shape[2]):\n",
    "                    gs[g].append(prior[chain,draw,g])\n",
    "\n",
    "        for g in gs:\n",
    "            plt.hist(g)\n",
    "        plt.show()\n",
    "\n",
    "        pred = posterior_predictive['posterior_predictive']['y_obs'].to_numpy()\n",
    "\n",
    "        shape = pred.shape\n",
    "        groups1 = shape[2]\n",
    "\n",
    "        # Initialize list of lists for each community\n",
    "        preds = [[] for _ in range(groups1)]\n",
    "\n",
    "        for i in range(shape[0]):\n",
    "            for j in range(shape[1]):\n",
    "                for k in range(groups1):\n",
    "                    preds[k].append(pred[i, j, k])\n",
    "\n",
    "        for k in range(groups1):\n",
    "\n",
    "            plt.hist(preds[k], bins=50, alpha=0.5)\n",
    "            plt.axvline(y[k], color='k', linestyle='dashed', linewidth=1)\n",
    "            plt.title('Group Interaction Predictions')\n",
    "            plt.xlabel(\"Number of interactions\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "            \n",
    "        print(az.summary(trace))\n",
    "\n",
    "        az.plot_trace(trace)\n",
    "        plt.show()\n",
    "        \n",
    "        trace_df = az.summary(trace)\n",
    "        trace_df.to_csv(f'{directory_name}/group_trace.csv')\n",
    "\n",
    "    \n",
    "    def user_choice_model(self,sim_number):\n",
    "        global g_y, g_y_pred, g_num_groups, g_users\n",
    "        directory_name = f\"{self.user_growth_rate}_{self.interaction_threshold}_{self.new_group_rate}_{self.new_community_rate}/{sim_number}\"\n",
    "        os.makedirs(directory_name, exist_ok=True)\n",
    "        # multinomial logit model for group interactions\n",
    "        num_groups = len(self.groups)\n",
    "        g_num_groups = num_groups\n",
    "        y = []\n",
    "        X = []\n",
    "\n",
    "        for user in self.users:\n",
    "            if len(user.interaction_history) == 0:\n",
    "                y.append(0)\n",
    "            else:\n",
    "                y.append(user.interaction_history[-1])\n",
    "            # every interaction but the last one\n",
    "            X.append(np.bincount(user.interaction_history[:-1], minlength=num_groups))\n",
    "\n",
    "\n",
    "        X = pd.DataFrame(X)\n",
    "        X.fillna(0, inplace=True)\n",
    "\n",
    "        y = pd.DataFrame(y)\n",
    "        y = y.iloc[:,0].to_numpy()        \n",
    "\n",
    "\n",
    "        # drop first column if sum is 0\n",
    "        if X.iloc[:,0].sum() == 0:\n",
    "            X = X.iloc[:,1:]\n",
    "            if num_groups < X.shape[1]:\n",
    "                num_groups += (X.shape[1] - num_groups)\n",
    "            elif num_groups > X.shape[1]:\n",
    "                num_groups -= (num_groups - X.shape[1])\n",
    "            \n",
    "            if X.shape[1] < np.max(y):\n",
    "                y -= (np.max(y)- X.shape[1]) \n",
    "\n",
    "        for row in range(len(X)):\n",
    "            X.iloc[row] = X.iloc[row] / X.iloc[row].sum()\n",
    "\n",
    "        X.fillna(0, inplace=True)\n",
    "        X = (X - X.mean()) / X.std()\n",
    "        X.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "        model = pm.Model()\n",
    "\n",
    "\n",
    "        with model:\n",
    "            try:\n",
    "\n",
    "                indices = pm.Data('index', list(range(len(X))), dims='user')\n",
    "                # Define your data within the model\n",
    "                X_data = pm.Data('X_data', X)\n",
    "                y_data = pm.Data('y_data', y)\n",
    "\n",
    "                unique_values, unique_counts = np.unique(y, return_counts=True)\n",
    "                print(\"unique counts\", unique_values)\n",
    "                print(\"unique values\", unique_counts)\n",
    "\n",
    "\n",
    "\n",
    "                # raise Exception\n",
    "\n",
    "                # Model parameters\n",
    "                \n",
    "                alpha = pm.Exponential('alpha', lam=.1, shape=num_groups)\n",
    "\n",
    "                beta_mu = pm.Normal('beta_mu', mu=1, sigma=10, shape=num_groups)\n",
    "                beta_sd = pm.TruncatedNormal('beta_sd', lower=0, mu=5, sigma=2.5, shape=num_groups)\n",
    "\n",
    "                beta = pm.Normal('beta', mu=beta_mu, sigma=beta_sd, shape=(num_groups, num_groups))\n",
    "\n",
    "                # Computing mu\n",
    "                mu = alpha + pm.math.dot(X_data, beta) \n",
    "\n",
    "                # A numerically stable softmax\n",
    "                mu_max = pm.math.max(mu, axis=1, keepdims=True)\n",
    "                p = pm.Deterministic('p', pm.math.exp(mu - mu_max) / pm.math.sum(pm.math.exp(mu - mu_max), axis=1, keepdims=True))\n",
    "\n",
    "                # Categorical distribution for observed data\n",
    "                y_obs = pm.Categorical('y_obs', p=p, observed=y_data, dims='user')\n",
    "\n",
    "                # Sampling\n",
    "                trace = pm.sample(tune=1000, draws=1000)\n",
    "                posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "                prior_predictive = pm.sample_prior_predictive()\n",
    "\n",
    "            except pm.exceptions.SamplingError:\n",
    "                model.debug(verbose=True)\n",
    "            \n",
    "            print(az.summary(trace))\n",
    "\n",
    "            # az.plot_trace(trace)\n",
    "            # plt.show()\n",
    "\n",
    "            g_y = y\n",
    "            g_y_pred = np.rint(posterior_predictive['posterior_predictive']['y_obs'].mean(axis=(0,1)))\n",
    "\n",
    "            y_pred = np.rint(posterior_predictive['posterior_predictive']['y_obs'].mean(axis=(0,1))) \n",
    "\n",
    "            print(az.summary(trace))\n",
    "\n",
    "            samples = posterior_predictive['posterior_predictive']['y_obs'].to_numpy()\n",
    "            users = [[] for _ in range(samples.shape[2])]\n",
    "            for chain in range(samples.shape[0]):\n",
    "                for draw in range(samples.shape[1]):\n",
    "                    for user in range(samples.shape[2]):\n",
    "                       users[user].append(samples[chain, draw, user])\n",
    "\n",
    "\n",
    "            # Define the grid layout\n",
    "            num_users = len(users)\n",
    "            num_rows = int(num_users**0.5)  # Number of rows in the grid\n",
    "            num_cols = (num_users + num_rows - 1) // num_rows  # Number of columns in the grid\n",
    "\n",
    "            # Create subplots\n",
    "            fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "\n",
    "            g_users = users\n",
    "\n",
    "            # Iterate through users and plot histograms\n",
    "            for user_idx, ax in enumerate(axes.flat):\n",
    "                if user_idx < num_users:\n",
    "                    user_data = users[user_idx]\n",
    "                    actual_interaction = y[user_idx]\n",
    "\n",
    "                    ax.hist(user_data, bins=num_groups)\n",
    "                    ax.axvline(actual_interaction, color='r', linestyle='dashed', linewidth=1)\n",
    "\n",
    "                    ax.set_title(f'User {user_idx + 1}')\n",
    "                    ax.set_xlabel('Interactions')\n",
    "                    ax.set_ylabel('Frequency')\n",
    "\n",
    "            # Remove any empty subplots\n",
    "            for user_idx in range(num_users, num_rows * num_cols):\n",
    "                fig.delaxes(axes.flat[user_idx])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            trace_df = az.summary(trace)\n",
    "            trace_df.to_csv(f'{directory_name}/user_trace.csv')\n",
    "\n",
    "sim = Simulation(50, 1.5, 1.01, 0.25, 0.1)\n",
    "sim.initialize()\n",
    "sim.run()\n",
    "\n",
    "sim_number = np.random.randint(1, 10000)\n",
    "\n",
    "sim.user_choice_model(sim_number)\n",
    "sim.community_regression_model(sim_number)\n",
    "sim.group_regression_model(sim_number)\n",
    "sim.plot(sim_number)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
