{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T18:55:24.756893Z",
     "start_time": "2023-12-06T18:55:23.835453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pystan in /Users/connorg0110/miniconda3/lib/python3.11/site-packages (2.19.1.1)\r\n",
      "Requirement already satisfied: Cython!=0.25.1,>=0.22 in /Users/connorg0110/miniconda3/lib/python3.11/site-packages (from pystan) (3.0.6)\r\n",
      "Requirement already satisfied: numpy>=1.7 in /Users/connorg0110/miniconda3/lib/python3.11/site-packages (from pystan) (1.26.1)\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stan'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[95], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m \n\u001B[1;32m     13\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpip install pystan\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstan\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnest_asyncio\u001B[39;00m\n\u001B[1;32m     16\u001B[0m nest_asyncio\u001B[38;5;241m.\u001B[39mapply()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'stan'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "from math import floor\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "#import pymc as pm\n",
    "import arviz as az\n",
    "import warnings\n",
    "import pandas as pd \n",
    "import stan\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# globals\n",
    "g_y = []\n",
    "g_y_pred = []\n",
    "g_num_groups = 0\n",
    "g_users = [] # model users\n",
    "s_users = [] # simulated users\n",
    "\n",
    "class Simulation:\n",
    "\n",
    "    ## Fixed hyperparameters\n",
    "    initial_users = 20\n",
    "    initial_groups = 6\n",
    "    initial_communities = 5\n",
    "\n",
    "    # group and community preferences\n",
    "    alpha_group_hyperparameter = 10\n",
    "    beta_group_hyperparameter = 10 \n",
    "\n",
    "    alpha_community_hyperparameter = 10\n",
    "    beta_community_hyperparameter = 10\n",
    "\n",
    "    comments_per_step = 2\n",
    "\n",
    "        \n",
    "    # Initialize lists to store users and groups\n",
    "    users = []\n",
    "    groups = []\n",
    "    communities = []\n",
    "\n",
    "\n",
    "    gis = {}\n",
    "    cis = {}\n",
    "    uis = {}\n",
    "\n",
    "    def __init__(self, num_timesteps, user_growth_rate, interaction_threshold, new_group_rate, new_community_rate) -> None:\n",
    "\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        self.user_growth_rate = user_growth_rate\n",
    "\n",
    "        self.interaction_threshold = interaction_threshold\n",
    "\n",
    "        self.new_group_rate = new_group_rate\n",
    "        self.new_group_join_chance = new_group_rate / 10\n",
    "\n",
    "        self.new_community_rate = new_community_rate\n",
    "        self.new_community_join_chance = new_community_rate / 10\n",
    "\n",
    "        self.same_community_interaction_ratio = new_community_rate * new_group_rate\n",
    "\n",
    "    class Community:\n",
    "        def __init__(self, simulation, group=None):\n",
    "            self.simulation = simulation \n",
    "            # Initialize a community with a list of users and groups\n",
    "            self.id = len(self.simulation.communities) + 1\n",
    "            self.groups = [group] if group else []\n",
    "            self.interactions = []\n",
    "\n",
    "    class Group:\n",
    "        def __init__(self, simulation):\n",
    "            self.simulation = simulation \n",
    "            # Initialize a group with an ID and a dictionary tgo track user interactions\n",
    "            self.id = len(self.simulation.groups)\n",
    "            self.interactions = {}\n",
    "            self.community = None\n",
    "\n",
    "        def join_community(self, community):\n",
    "            community.groups.append(self)\n",
    "            self.community = community\n",
    "\n",
    "    class User:\n",
    "        def __init__(self, group_alpha, group_beta, community_alpha, community_beta):\n",
    "            # Initialize a user with ID, group memberships, interaction history, and Beta distribution preferences\n",
    "            self.id = None\n",
    "\n",
    "            self.groups = []\n",
    "            self.communities = []\n",
    "            self.interaction_history = []\n",
    "\n",
    "            self.group_preferences = stats.beta(group_alpha, group_beta)\n",
    "            self.community_preferences = stats.beta(community_alpha, community_beta)\n",
    "            self.updated_preferences = np.array([1])\n",
    "\n",
    "        def update_preferences(self):\n",
    "            # Update user's preferences based on group interactions\n",
    "            if not self.groups:\n",
    "                self.updated_preferences = np.array([1])\n",
    "                return\n",
    "            else:\n",
    "                #sort groups by number of interactions\n",
    "                self.groups.sort(key=lambda group: len(group.interactions))\n",
    "\n",
    "            total_size = sum([len(group.interactions) for group in self.groups])\n",
    "\n",
    "            # if size is 0, this must be the first iteration, return uniform\n",
    "            if total_size == 0:\n",
    "                self.ccdf = np.array([1])\n",
    "                return\n",
    "            else:\n",
    "                sizes = sorted([len(group.interactions) for group in self.groups])\n",
    "                self.ccdf = 1 - (np.cumsum(sizes) / total_size)\n",
    "\n",
    "            group_convolution = np.convolve(self.group_preferences.pdf(np.linspace(0, 1, len(self.groups))), self.ccdf , mode='same')\n",
    "\n",
    "            self.updated_preferences = np.convolve(group_convolution, self.community_preferences.pdf(np.linspace(0, 1, len(self.groups))), mode='same')\n",
    "\n",
    "            if np.isnan(self.updated_preferences).any() or np.sum(self.updated_preferences) == 0:\n",
    "                self.updated_preferences = np.array([1 / len(self.groups)] * len(self.groups))\n",
    "            else:\n",
    "                self.updated_preferences /= np.sum(self.updated_preferences)\n",
    "\n",
    "        def join_group(self, group):\n",
    "            # Add a group to the user's group list and set initial interactions to 0\n",
    "            self.groups.append(group)\n",
    "            group.interactions[self] = 0\n",
    "\n",
    "        def interact(self, group):\n",
    "            # Record an interaction with the specified group\n",
    "            group.interactions[self] = group.interactions.get(self, 0) + 1\n",
    "            self.interaction_history.append(group.id)\n",
    "            # if group.id == 0:\n",
    "            #     print(\"A\", self.interaction_history[-1])\n",
    "\n",
    "    # Recalculate probabilities at every iteration or after any changes\n",
    "    def calculate_probabilities(self):\n",
    "        global community_relative_frequency, group_relative_frequency\n",
    "\n",
    "        community_relative_frequency = np.array([len(community.groups) for community in self.communities], dtype=float)\n",
    "        # if community_relative_frequency.sum() != 0:\n",
    "        community_relative_frequency += 1e-5  # Avoid division by zero\n",
    "        community_relative_frequency /= community_relative_frequency.sum()\n",
    "\n",
    "        group_relative_frequency = np.array([sum(group.interactions.values()) for group in self.groups], dtype=float)\n",
    "        # if group_relative_frequency.sum() != 0:\n",
    "        group_relative_frequency += 1e-5\n",
    "        group_relative_frequency /= group_relative_frequency.sum()\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "\n",
    "        # Initialize users\n",
    "        for i in range(self.initial_users):\n",
    "            self.users.append(\n",
    "                self.User(\n",
    "                    self.alpha_group_hyperparameter,\n",
    "                    self.beta_group_hyperparameter,\n",
    "                    self.alpha_community_hyperparameter,\n",
    "                    self.beta_community_hyperparameter,\n",
    "                )\n",
    "            )\n",
    "            self.users[-1].id = len(self.users)\n",
    "\n",
    "        # Initialize communities\n",
    "        for i in range(self.initial_communities):\n",
    "            self.communities.append(self.Community(self))\n",
    "\n",
    "        # Initialize groups\n",
    "        for i in range(self.initial_groups):\n",
    "            self.groups.append(self.Group(self))\n",
    "\n",
    "        # adding the first groups to each community so there is at least one group in each community\n",
    "        for i in range(len(self.communities)):\n",
    "            self.groups[i].join_community(self.communities[i])\n",
    "            # random chance for each user to join the first group of a new community\n",
    "            for user in self.users:\n",
    "                if np.random.random() < self.new_community_join_chance:\n",
    "                    user.join_group(self.groups[i])\n",
    "\n",
    "        # randomly adding the rest of the groups to communities\n",
    "        for group in self.groups[len(self.communities):]:\n",
    "            group.join_community(self.communities[np.random.randint(0, len(self.communities))])\n",
    "            for user in self.users:\n",
    "                if np.random.random() < self.new_group_join_chance:\n",
    "                    user.join_group(group)\n",
    "\n",
    "        # initialize dictionaries for each group, community, and user\n",
    "        for group in self.groups:\n",
    "            self.gis[group.id] = []\n",
    "        for community in self.communities:\n",
    "            self.cis[community.id] = []\n",
    "        for user in self.users:\n",
    "            self.uis[user.id] = []\n",
    "\n",
    "        \n",
    "    def run(self):\n",
    "        global s_users\n",
    "        # main loop\n",
    "        for time in range(self.num_timesteps):\n",
    "            # if time % 10 == 0:\n",
    "            #     print(f\"Step: {time}\", end = \"\\r\")\n",
    "            # Calculate probabilities\n",
    "            self.calculate_probabilities()\n",
    "\n",
    "            # Add new users\n",
    "            new_users_count = floor(np.random.exponential(self.user_growth_rate))\n",
    "            for i in range(new_users_count):\n",
    "                self.users.append(\n",
    "                    self.User(\n",
    "                        self.alpha_group_hyperparameter,\n",
    "                        self.beta_group_hyperparameter,\n",
    "                        self.alpha_community_hyperparameter,\n",
    "                        self.beta_community_hyperparameter,\n",
    "                    )\n",
    "                )\n",
    "                self.users[-1].id = len(self.users)\n",
    "\n",
    "            # Add new groups\n",
    "            new_groups_count = floor(np.random.exponential(self.new_group_rate))\n",
    "            for i in range(new_groups_count):\n",
    "                self.groups.append(self.Group(self))\n",
    "\n",
    "                # a new community always get made on the first time step\n",
    "                if time == 0:\n",
    "                    if new_groups_count == 0:\n",
    "                        self.groups.append(self.Group(self))\n",
    "                    self.groups[-1].join_community(self.communities[-1])\n",
    "                    self.communities[-1].groups.append(self.groups[-1])\n",
    "                else:\n",
    "                    # check if the new group forms a new community\n",
    "                    if np.random.random() < self.new_community_rate:\n",
    "                        self.communities.append(self.Community(self, self.groups[-1]))\n",
    "                        self.groups[-1].community = self.communities[-1]\n",
    "                        # each user has a chance to join the new community\n",
    "                        for user in self.users:\n",
    "                            if np.random.random() < self.new_community_join_chance:\n",
    "                                user.join_group(self.groups[-1])\n",
    "                        # users[np.random.randint(0, len(users))].join_group(groups[-1])\n",
    "                    else:\n",
    "                        # join a random community\n",
    "                        self.groups[-1].join_community(self.communities[np.random.randint(0, len(self.communities))])\n",
    "\n",
    "            # Updating dictionaries with new groups, communities, and users\n",
    "            # and setting their initial values to 0\n",
    "            for group in self.groups:\n",
    "                if group.id not in self.gis:\n",
    "                    self.gis[group.id] = [0]\n",
    "                self.gis[group.id].append(0)\n",
    "            for community in self.communities:\n",
    "                if community.id not in self.cis:\n",
    "                    self.cis[community.id] = [0]\n",
    "                self.cis[community.id].append(0)\n",
    "            for user in self.users:\n",
    "                if user.id not in self.uis:\n",
    "                    self.uis[user.id] = [0]\n",
    "                self.uis[user.id].append(0)\n",
    "\n",
    "            # Add new users to groups\n",
    "            for user in self.users:\n",
    "                self.calculate_probabilities()\n",
    "                # if there are groups for the user to join that they aren't in\n",
    "                # if a user is not in any group, they are guaranteed to join a group\n",
    "                if len(user.groups) == 0:\n",
    "                    user.join_group(self.groups[np.random.choice(len(self.groups), p=group_relative_frequency)])\n",
    "                else:\n",
    "                    if len(user.groups) < len(self.groups):\n",
    "                        # join a group\n",
    "                        if np.random.random() < self.new_group_join_chance:\n",
    "                            user.join_group(self.groups[np.random.choice(len(self.groups), p=group_relative_frequency)])\n",
    "\n",
    "            # Interact with groups\n",
    "            for user in self.users:\n",
    "                for _ in range(self.comments_per_step):\n",
    "                    user.update_preferences()\n",
    "                    interacted_groups = []\n",
    "                    if np.random.uniform() < self.interaction_threshold and user.groups:\n",
    "                        # print(user.updated_preferences)\n",
    "                        group = np.random.choice(user.groups, p=user.updated_preferences)\n",
    "                        # if group.id == 0:\n",
    "                        #     print(\"Group 0\")\n",
    "                        user.interact(group)\n",
    "                        self.gis[group.id][-1] += 1\n",
    "                        self.cis[group.community.id][-1] += 1\n",
    "                        self.uis[user.id][-1] += 1\n",
    "\n",
    "                        # potential bonus interactions within another group in the same community\n",
    "                        if group.community:\n",
    "                            while True:\n",
    "                                if np.random.uniform() < self.same_community_interaction_ratio:\n",
    "                                    community = group.community                    \n",
    "                                    group = np.random.choice(community.groups)\n",
    "                                    user.interact(group)\n",
    "                                    self.gis[group.id][-1] += 1\n",
    "                                    self.cis[group.community.id][-1] += 1\n",
    "                                    self.uis[user.id][-1] += 1\n",
    "                                else:\n",
    "                                    break\n",
    "\n",
    "            # Update user preferences\n",
    "            for user in self.users:\n",
    "                if user.groups:\n",
    "                    user.update_preferences()\n",
    "                    if user.id == 0:\n",
    "                        print(user.updated_preferences)\n",
    "                        print(user.group_preferences.pdf(np.linspace(0, 1, len(user.groups))))\n",
    "                else:\n",
    "                    user.updated_preferences = np.array([1])\n",
    "\n",
    "    def plot(self, sim_number):        \n",
    "        directory_name = f\"{self.user_growth_rate}_{self.interaction_threshold}_{self.new_group_rate}_{self.new_community_rate}/{sim_number}\"\n",
    "        os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "        c_sum = []\n",
    "        c_sum_labels = []\n",
    "        for i in range(len(self.communities)):\n",
    "            temp_sum = [0] * self.num_timesteps\n",
    "            c_vals = np.cumsum(self.cis[i+1])\n",
    "            # add the values starting from the back\n",
    "            for j, val in enumerate(reversed(c_vals)):\n",
    "                temp_sum[-1-j] = val\n",
    "            c_sum.append(temp_sum)\n",
    "            c_sum_labels.append(list(self.cis.keys())[i])\n",
    "\n",
    "        # print the final value for each community\n",
    "        for c in c_sum_labels[:5]:\n",
    "            print(c, c_sum[c_sum_labels.index(c)][-1])\n",
    "            \n",
    "        # finding the labels for the 5 largest communities\n",
    "        top_5 = []\n",
    "        top_5_labels = []\n",
    "        for i in range(5):\n",
    "            max_val = 0\n",
    "            max_index = 0\n",
    "            for j in range(len(c_sum)):\n",
    "                if c_sum[j][-1] > max_val and c_sum_labels[j] not in top_5_labels:\n",
    "                    max_val = c_sum[j][-1]\n",
    "                    max_index = j\n",
    "            top_5.append(c_sum[max_index])\n",
    "            top_5_labels.append(c_sum_labels[max_index])\n",
    "\n",
    "        for i in range(len(c_sum)):\n",
    "            if c_sum_labels[i] in top_5_labels:\n",
    "                plt.plot(c_sum[i][:len(c_sum[i])], label=f\"C{i+1}\")\n",
    "            else:\n",
    "                plt.plot(c_sum[i][:len(c_sum[i])], label=None)\n",
    "\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Cumulative Interactions\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.title(\"Cumulative Interactions of Each Community Over Time\")\n",
    "        plt.savefig(f\"{directory_name}/community_interaction_growth.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Scatter plot for final amount of interactions for each community\n",
    "        c_sum_final = []\n",
    "        c_sum_final_labels = []\n",
    "        for i in range(len(self.communities)):\n",
    "            c_sum_final.append(c_sum[i][-1])\n",
    "            c_sum_final_labels.append(list(self.cis.keys())[i])\n",
    "\n",
    "        plt.scatter(c_sum_final_labels, c_sum_final)\n",
    "        plt.xlabel(\"Community\")\n",
    "        plt.ylabel(\"Final Cumulative Interactions\")\n",
    "        plt.title(\"Final Cumulative Interactions of Each Community\")\n",
    "        plt.savefig(f\"{directory_name}/final_community_interactions.png\")\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "        g_sum = []\n",
    "        g_sum_labels = []\n",
    "        for i in range(1, len(self.groups)):\n",
    "            temp_sum = [0] * self.num_timesteps\n",
    "            g_vals = np.cumsum(self.gis[i])\n",
    "            # add the values starting from the back\n",
    "            for j, val in enumerate(reversed(g_vals)):\n",
    "                try:\n",
    "                    temp_sum[j] = val\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            temp_sum = temp_sum[::-1]\n",
    "            g_sum.append(temp_sum)\n",
    "            g_sum_labels.append(list(self.gis.keys())[i])\n",
    "\n",
    "        # print the final value for each group\n",
    "        for g in g_sum_labels[:5]:\n",
    "            print(g, g_sum[g_sum_labels.index(g)][-1])\n",
    "\n",
    "        # finding the labels for the 5 largest groups\n",
    "        top_5 = []\n",
    "        top_5_labels = []\n",
    "        for i in range(5):\n",
    "            max_val = 0\n",
    "            max_index = 0\n",
    "            for j in range(len(g_sum)):\n",
    "                if g_sum[j][-1] > max_val and g_sum_labels[j] not in top_5_labels:\n",
    "                    max_val = g_sum[j][-1]\n",
    "                    max_index = j\n",
    "            top_5.append(g_sum[max_index])\n",
    "            top_5_labels.append(g_sum_labels[max_index])\n",
    "\n",
    "        for i in range(len(g_sum)):\n",
    "            if g_sum_labels[i] in top_5_labels:\n",
    "                plt.plot(g_sum[i], label=f\"G{i+1}\")\n",
    "            else:\n",
    "                plt.plot(g_sum[i], label=None)\n",
    "\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Cumulative Interactions\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.ylim(bottom=1)\n",
    "        plt.title(\"Cumulative Interactions of Each Group Over Time\")\n",
    "        plt.savefig(f\"{directory_name}/group_interaction_growth.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Scatter plot for final amount of interactions for each group\n",
    "        g_sum_final = []\n",
    "        g_sum_final_labels = []\n",
    "        for i in range(len(g_sum)):\n",
    "            g_sum_final.append(g_sum[i][-1])\n",
    "            g_sum_final_labels.append(list(self.gis.keys())[i])\n",
    "\n",
    "        plt.scatter(g_sum_final_labels, g_sum_final)\n",
    "        plt.xlabel(\"Group\")\n",
    "        plt.ylabel(\"Final Cumulative Interactions\")\n",
    "        plt.title(\"Final Cumulative Interactions of Each Group\")\n",
    "        plt.savefig(f\"{directory_name}/final_group_interactions.png\")\n",
    "        plt.close()\n",
    "\n",
    "        for u in self.uis:\n",
    "            self.uis[u] = self.uis[u][:self.num_timesteps]\n",
    "\n",
    "        # plotting total amount of interactions for each user\n",
    "        u_sum = []\n",
    "        u_sum_labels = []\n",
    "        for i in range(1, len(self.users)):\n",
    "            temp_sum = [0] * self.num_timesteps\n",
    "            u_vals = np.cumsum(self.uis[i])\n",
    "            # add the values starting from the back\n",
    "            for j, val in enumerate(reversed(u_vals)):\n",
    "                temp_sum[j] = val\n",
    "\n",
    "            temp_sum = temp_sum[::-1]\n",
    "            u_sum.append(temp_sum)\n",
    "            u_sum_labels.append(list(self.uis.keys())[i])\n",
    "\n",
    "        # print the final value for each user\n",
    "        for u in u_sum_labels[:5]:\n",
    "            print(u, u_sum[u_sum_labels.index(u)][-1])\n",
    "\n",
    "        # finding the labels for the 5 largest users\n",
    "        top_5 = []\n",
    "        top_5_labels = []\n",
    "\n",
    "        for i in range(5):\n",
    "            max_val = 0\n",
    "            max_index = 0\n",
    "            for j in range(len(u_sum)):\n",
    "                if u_sum[j][-1] > max_val and u_sum_labels[j] not in top_5_labels:\n",
    "                    max_val = u_sum[j][-1]\n",
    "                    max_index = j\n",
    "            top_5.append(u_sum[max_index])\n",
    "            top_5_labels.append(u_sum_labels[max_index])\n",
    "\n",
    "        # Scatter plot for final amount of interactions for each user\n",
    "        u_sum_final = []\n",
    "        u_sum_final_labels = []\n",
    "        for i in range(len(u_sum)):\n",
    "            u_sum_final.append(u_sum[i][-1])\n",
    "            u_sum_final_labels.append(list(self.uis.keys())[i])\n",
    "\n",
    "        plt.scatter(u_sum_final_labels, u_sum_final)\n",
    "        plt.xlabel(\"User\")\n",
    "        plt.ylabel(\"Final Cumulative Interactions\")\n",
    "        plt.title(\"Cumulative Interactions of Each User\")\n",
    "        plt.savefig(f\"{directory_name}/final_user_interactions.png\")\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    def write_data(self, sim_number):\n",
    "        directory_name = f\"{self.user_growth_rate}_{self.interaction_threshold}_{self.new_group_rate}_{self.new_community_rate}/{sim_number}\"\n",
    "        os.makedirs(directory_name, exist_ok=True)\n",
    "\n",
    "        # Write User Interactions to CSV\n",
    "        with open(f\"{directory_name}/user_interactions.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row in range(1, 1 + len(list(self.uis.keys()))):\n",
    "                writer.writerow([row] + [0 for _ in range(self.num_timesteps-len(self.uis[row])) ] + self.uis[row])\n",
    "\n",
    "            file.close()\n",
    "        \n",
    "        # Write Group Interactions to CSV\n",
    "        with open(f\"{directory_name}/group_interactions.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row in range(len(list(self.gis.keys()))):\n",
    "                writer.writerow([row] + [0 for _ in range(self.num_timesteps-len(self.gis[row])) ] + self.gis[row])\n",
    "\n",
    "            file.close()\n",
    "\n",
    "        # Write Community Interactions to CSV\n",
    "        with open(f\"{directory_name}/community_interactions.csv\", 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row in range(1, 1 + len(list(self.cis.keys()))):\n",
    "                writer.writerow([row] + [0 for _ in range(self.num_timesteps-len(self.cis[row])) ] + self.cis[row])\n",
    "\n",
    "            file.close()\n",
    "\n",
    "\n",
    "        with open(f\"{directory_name}/simulation_data.csv\", 'w') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['num_users', 'num_groups', 'num_communities', 'num_interactions'])\n",
    "            writer.writerow([len(self.users), len(self.groups), len(self.communities), sum([len(group.interactions) for group in self.groups])])\n",
    "\n",
    "            file.close()\n",
    "\n",
    "        print(\"Data written to CSV files.\")\n",
    "\n",
    "    def community_regression_model(self):\n",
    "\n",
    "        y = []\n",
    "        X = pd.DataFrame()\n",
    "        g_sum = 0\n",
    "\n",
    "\n",
    "        for community in range(len(self.communities)):\n",
    "            df = pd.DataFrame(self.gis[community + 1]) \n",
    "            df.fillna(0, inplace=True)\n",
    "            if len(df)<self.num_timesteps:\n",
    "                df = df.reindex(range(self.num_timesteps), fill_value=0)\n",
    "            X[community] = df.squeeze()  \n",
    "\n",
    "        \n",
    "        y=X.iloc[-1:, :].values\n",
    "        \n",
    "        X = X.iloc[0:99,:]\n",
    "\n",
    "        print(type(X))\n",
    "        y = y[0]\n",
    "    \n",
    "        print(y)\n",
    "        print(type(y))\n",
    "        X= X.T\n",
    "        X = X.to_numpy()\n",
    "        print(X)\n",
    "        rows, cols = np.shape(X)\n",
    "        print(rows)\n",
    "        print(cols)\n",
    "\n",
    "        \n",
    "\n",
    "        prior_predictive =\"\"\"\n",
    "\n",
    "        data {\n",
    "            int<lower = 0> N;\n",
    "            int<lower = 0> K;\n",
    "            matrix[K,N]X; // group matrix\n",
    "\n",
    "            }\n",
    "        generated quantities {\n",
    "            real alpha = normal_rng(0, 1);\n",
    "            real beta = normal_rng(0, 1);\n",
    "            real<lower = 0> sigma = exponential_rng(1);\n",
    "            real X \n",
    "            for (n in 1:N) {\n",
    "                for (k in 1:K) {\n",
    "                    real Y_pred = normal_rng(alpha+beta*X[k,n-1], sigma);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        #model_prior = stan.build(prior_predictive, data={'N': cols, 'K': rows, 'X':X},random_seed=1)\n",
    "        #prior_fit = model_prior.sample(num_chains=4, num_samples=1000)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        s_code = \"\"\"\n",
    "        data {\n",
    "            int<lower=0> N; // number of data points\n",
    "            int<lower=0> K; // number of communities\n",
    "            int y[K]; // data matrix \n",
    "            matrix[K,N]X; // group matrix\n",
    "            \n",
    "\n",
    "        }\n",
    "        parameters {\n",
    "            vector<lower=0>[K] sigma;\n",
    "            vector[K] beta;\n",
    "            vector[K] alpha;\n",
    "        }\n",
    "        model {\n",
    "            beta ~ normal(0, 1);\n",
    "            alpha ~ normal(0, 1);\n",
    "            sigma ~ exponential(1);\n",
    "\n",
    "            \n",
    "            for (i in 1:K) {\n",
    "                for (n in 2:N) {\n",
    "                    X[i,n] ~ normal(alpha+beta*X[i,n-1], sigma);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        model = stan.build(s_code,data={'N': cols, 'K': rows, 'y':y, 'X':X},random_seed=1)\n",
    "        fit = model.sample(num_chains=4, num_samples=1000)\n",
    "        # Check convergence\n",
    "        fit_simple_az = az.from_pystan(fit)\n",
    "        \n",
    "        print(az.summary(fit_simple_az))\n",
    "\n",
    "\n",
    "        az.plot_trace(fit_simple_az, var_names=['alpha', 'beta', 'sigma']);\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        # Posterior Predictive\n",
    "        #az.plot_ppc(fit_simple_az, data_pairs={'y': 'y_pred'});\n",
    "        # plt.tight_layout()\n",
    "        #plt.show()\n",
    "\n",
    "        # any diverging transitions?\n",
    "        print(\"Number of diverging samples: {}\".format(fit['divergent__'].sum()))\n",
    "\n",
    "        print(fit['alpha'].shape)\n",
    "        alpha_mean = fit['alpha'].mean(axis=1)\n",
    "        beta_mean = fit['beta'].mean(axis=1)\n",
    "        sigma_mean = fit['sigma'].mean(axis=1)\n",
    "\n",
    "        print(alpha_mean)\n",
    "        print(beta_mean)\n",
    "        print(sigma_mean)\n",
    "        y_pred = []\n",
    "        #Posterior Predictive\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(alpha_mean)):\n",
    "            \n",
    "            y_est= np.random.normal(alpha_mean[i] + beta_mean[i]*X[i][-1], sigma_mean[i],1000)\n",
    "            y_pred.append(y_est)\n",
    "            plt.hist(y_est, bins=50, alpha=0.5)\n",
    "            plt.axvline(y[i], color='k', linestyle='dashed', linewidth=1)\n",
    "            plt.title('Community Interaction Posterior Predictions')\n",
    "            plt.xlabel(\"Number of interactions\")\n",
    "\n",
    "        \n",
    "        print(y_pred)\n",
    "        print(y)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        sns.kdeplot(fit['sigma'][0, :])\n",
    "        plt.xlabel(r\"$\\sigma$\")\n",
    "        plt.ylabel(\"Posterior density\")\n",
    "        sns.despine()\n",
    "        plt.show()\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    def group_regression_model(self):\n",
    "\n",
    "        y = []\n",
    "        X = pd.DataFrame()\n",
    "        g_sum = 0\n",
    "\n",
    "\n",
    "        for group in range(len(self.groups)):\n",
    "            df = pd.DataFrame(self.gis[group]) \n",
    "            df.fillna(0, inplace=True)\n",
    "            if len(df)<self.num_timesteps:\n",
    "                df = df.reindex(range(self.num_timesteps), fill_value=0)\n",
    "            X[group] = df.squeeze()   \n",
    "\n",
    "        y=X.iloc[-1:, :].values\n",
    "        \n",
    "        X = X.iloc[:-1,:]\n",
    "\n",
    "        print(type(X))\n",
    "        y = y[0]\n",
    "    \n",
    "        print(y)\n",
    "        print(type(y))\n",
    "        X= X.T\n",
    "        X = X.to_numpy()\n",
    "        print(X)\n",
    "        rows, cols = np.shape(X)\n",
    "        print(rows)\n",
    "        print(cols)\n",
    "\n",
    "        \n",
    "\n",
    "        prior_predictive =\"\"\"\n",
    "\n",
    "        data {\n",
    "            int<lower = 0> N;\n",
    "            int<lower = 0> K;\n",
    "            matrix[K,N]X; // group matrix\n",
    "\n",
    "            }\n",
    "        generated quantities {\n",
    "            real alpha = normal_rng(0, 1);\n",
    "            real beta = normal_rng(0, 1);\n",
    "            real<lower = 0> sigma = exponential_rng(1);\n",
    "            real X \n",
    "            for (n in 1:N) {\n",
    "                for (k in 1:K) {\n",
    "                    real Y_pred = normal_rng(alpha+beta*X[k,n-1], sigma);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        #model_prior = stan.build(prior_predictive, data={'N': cols, 'K': rows, 'X':X},random_seed=1)\n",
    "        #prior_fit = model_prior.sample(num_chains=4, num_samples=1000)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        s_code = \"\"\"\n",
    "        data {\n",
    "            int<lower=0> N; // number of data points\n",
    "            int<lower=0> K; // number of communities \n",
    "            matrix<lower = 0>[K,N]X ; // group matrix\n",
    "            \n",
    "            \n",
    "\n",
    "        }\n",
    "        parameters {\n",
    "            vector<lower=0>[K] sigma;\n",
    "            vector[K] beta;\n",
    "            vector[K] alpha;\n",
    "            \n",
    "        }\n",
    "        model {\n",
    "            beta ~ normal(0, 1);\n",
    "            alpha ~ normal(0, 1);\n",
    "            sigma ~ exponential(1.5);\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            for (i in 1:K) {\n",
    "                for (n in 2:N) {\n",
    "                    X[i,n] ~ normal(alpha+beta*X[i,n-1], sigma);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        model = stan.build(s_code,data={'N': cols, 'K': rows,'X':X},random_seed=1)\n",
    "        fit = model.sample(num_chains=4, num_samples=1000)\n",
    "        # Check convergence\n",
    "        fit_simple_az = az.from_pystan(fit)\n",
    "        \n",
    "        print(az.summary(fit_simple_az))\n",
    "\n",
    "\n",
    "        az.plot_trace(fit_simple_az, var_names=['alpha', 'beta', 'sigma']);\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        # Posterior Predictive\n",
    "        #az.plot_ppc(fit_simple_az, data_pairs={'y': 'y_pred'});\n",
    "        # plt.tight_layout()\n",
    "        #plt.show()\n",
    "\n",
    "        # any diverging transitions?\n",
    "        print(\"Number of diverging samples: {}\".format(fit['divergent__'].sum()))\n",
    "\n",
    "        print(fit['alpha'].shape)\n",
    "        alpha_mean = fit['alpha'].mean(axis=1)\n",
    "        beta_mean = fit['beta'].mean(axis=1)\n",
    "        sigma_mean = fit['sigma'].mean(axis=1)\n",
    "\n",
    "        print(alpha_mean)\n",
    "        print(beta_mean)\n",
    "        print(sigma_mean)\n",
    "        y_pred = []\n",
    "        #Posterior Predictive\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(alpha_mean)):\n",
    "            \n",
    "            y_est= np.random.normal(alpha_mean[i] + beta_mean[i]*X[i][-1], sigma_mean[i],1000)\n",
    "            y_pred.append(y_est)\n",
    "            plt.hist(y_est, bins=50, alpha=0.5)\n",
    "            plt.axvline(y[i], color='k', linestyle='dashed', linewidth=1)\n",
    "            plt.title('Group Interaction Posterior Predictions')\n",
    "            plt.xlabel(\"Number of interactions\")\n",
    "\n",
    "        \n",
    "        print(y_pred)\n",
    "        print(y)\n",
    "       \n",
    "        \n",
    "results = []\n",
    "\n",
    "#sim = Simulation(1, 0.2, .2, 0.25)\n",
    "\n",
    "sim = Simulation(100,1, 1, .2, 0.1)\n",
    "sim.initialize()\n",
    "sim.run()\n",
    "#sim.community_regression_model()\n",
    "sim.group_regression_model()\n",
    "sim.write_data(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sim.group_regression_model()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-04T20:54:31.062181Z",
     "start_time": "2023-12-04T20:54:31.056545Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T18:46:20.910138Z",
     "start_time": "2023-12-06T18:46:20.893335Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'groups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[89], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# multinomial logit model for group interactions\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m num_groups \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mgroups\u001B[49m)\n\u001B[1;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      4\u001B[0m X \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mNameError\u001B[0m: name 'groups' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# multinomial logit model for group interactions\n",
    "num_groups = len(groups)\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "for user in users:\n",
    "    y.append(user.interaction_history[-1])\n",
    "    # every interaction but the last one\n",
    "    X.append(np.bincount(user.interaction_history[:-1], minlength=num_groups))\n",
    "\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "y = pd.DataFrame(y)\n",
    "y = y.iloc[:,0]\n",
    "\n",
    "# drop first column if sum is 0\n",
    "if X.iloc[:,0].sum() == 0:\n",
    "    X = X.iloc[:,1:]\n",
    "    if num_groups != X.shape[1]:\n",
    "        num_groups -= (X.shape[1] - num_groups)\n",
    "\n",
    "for row in range(len(X)):\n",
    "    X.iloc[row] = X.iloc[row] / X.iloc[row].sum()\n",
    "\n",
    "X.fillna(0, inplace=True)\n",
    "X = (X - X.mean()) / X.std()\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "model = pm.Model()\n",
    "\n",
    "\n",
    "with model:\n",
    "    try:\n",
    "\n",
    "        indices = pm.Data('index', list(range(len(X))), dims='user')\n",
    "        # Define your data within the model\n",
    "        X_data = pm.Data('X_data', X)\n",
    "        y_data = pm.Data('y_data', y)\n",
    "\n",
    "        # Model parameters\n",
    "        \n",
    "        alpha = pm.Exponential('alpha', lam=np.max(group_relative_frequency), shape=num_groups)\n",
    "\n",
    "        beta_mu = pm.Normal('beta_mu', mu=1, sigma=10, shape=num_groups)\n",
    "        beta_sd = pm.TruncatedNormal('beta_sd', lower=0, mu=5, sigma=2.5, shape=num_groups)\n",
    "\n",
    "        beta = pm.Normal('beta', mu=beta_mu, sigma=beta_sd, shape=(num_groups, num_groups))\n",
    "\n",
    "        # Computing mu\n",
    "        mu = alpha + pm.math.dot(X_data, beta) \n",
    "\n",
    "        # A numerically stable softmax\n",
    "        mu_max = pm.math.max(mu, axis=1, keepdims=True)\n",
    "        p = pm.Deterministic('p', pm.math.exp(mu - mu_max) / pm.math.sum(pm.math.exp(mu - mu_max), axis=1, keepdims=True))\n",
    "\n",
    "        # Categorical distribution for observed data\n",
    "        y_obs = pm.Categorical('y_obs', p=p, observed=y_data, dims='user')\n",
    "\n",
    "        # Sampling\n",
    "        trace = pm.sample(tune=5000, draws=5000)\n",
    "        posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "        prior_predictive = pm.sample_prior_predictive()\n",
    "\n",
    "    except pm.exceptions.SamplingError:\n",
    "        model.debug(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(az.summary(trace))\n",
    "\n",
    "y_pred = np.rint(posterior_predictive['posterior_predictive']['y_obs'].mean(axis=(0,1))) \n",
    "\n",
    "plt.scatter(y, y_pred)\n",
    "plt.xlabel('Actual Group ID')\n",
    "plt.ylabel('Predicted Group ID')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(y, y_pred - y)\n",
    "plt.xlabel('Actual Group ID')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()\n",
    "\n",
    "print(az.summary(trace))\n",
    "\n",
    "plt.hist(y_pred, bins=num_groups, alpha=0.5, label='Predicted')\n",
    "plt.hist(y,  bins=num_groups, alpha=0.5, label='Actual')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Group ID\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "samples = posterior_predictive['posterior_predictive']['y_obs'].to_numpy()\n",
    "users = [[] for _ in range(samples.shape[2])]\n",
    "for chain in range(samples.shape[0]):\n",
    "  for draw in range(samples.shape[1]):\n",
    "    for user in range(samples.shape[2]):\n",
    "      users[user].append(samples[chain, draw, user])\n",
    "\n",
    "\n",
    "# Define the grid layout\n",
    "num_users = len(users)\n",
    "num_rows = int(num_users**0.5)  # Number of rows in the grid\n",
    "num_cols = (num_users + num_rows - 1) // num_rows  # Number of columns in the grid\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "\n",
    "# Iterate through users and plot histograms\n",
    "for user_idx, ax in enumerate(axes.flat):\n",
    "    if user_idx < num_users:\n",
    "        user_data = users[user_idx]\n",
    "        actual_interaction = y[user_idx]\n",
    "\n",
    "        ax.hist(user_data, bins=num_groups)\n",
    "        ax.axvline(actual_interaction, color='r', linestyle='dashed', linewidth=1)\n",
    "\n",
    "        ax.set_title(f'User {user_idx + 1}')\n",
    "        ax.set_xlabel('Interactions')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for user_idx in range(num_users, num_rows * num_cols):\n",
    "    fig.delaxes(axes.flat[user_idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
